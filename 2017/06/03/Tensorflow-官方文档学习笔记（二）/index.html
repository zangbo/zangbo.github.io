<!DOCTYPE html>
<html lang="zh-Hans">
<head>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="ZangBo" />



<meta name="description" content="本系列是对TensorFlow官方文档进行学习的总结，本篇介绍了利用TensorFlow搭建一个卷积神经网络，并用它来对MNIST数据集进行分类。">
<meta name="keywords" content="TensorFlow">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow 笔记（二）">
<meta property="og:url" content="http://zangbo.me/2017/06/03/Tensorflow-官方文档学习笔记（二）/index.html">
<meta property="og:site_name" content="ZangBo&#39;s Home">
<meta property="og:description" content="本系列是对TensorFlow官方文档进行学习的总结，本篇介绍了利用TensorFlow搭建一个卷积神经网络，并用它来对MNIST数据集进行分类。">
<meta property="og:updated_time" content="2017-06-24T17:31:29.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow 笔记（二）">
<meta name="twitter:description" content="本系列是对TensorFlow官方文档进行学习的总结，本篇介绍了利用TensorFlow搭建一个卷积神经网络，并用它来对MNIST数据集进行分类。">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="ZangBo&#39;s Home" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.ico">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">




<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>TensorFlow 笔记（二） | ZangBo&#39;s Home</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script>
        yiliaConfig.jquery_ui = [true, "//cdn.bootcss.com/jqueryui/1.10.4/jquery-ui.min.js", "//cdn.bootcss.com/jqueryui/1.10.4/css/jquery-ui.min.css"];
    </script>



    <script> yiliaConfig.rootUrl = "\/";</script>





    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?2697f2f0e109a018f0f89683fab342e6";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
        })();
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</head>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div style="display: none"><img src="/img/sharing.jpg" /></div>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.jpg" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">ZangBo</a></h1>
        </hgroup>

        
        
        <p class="header-subtitle">永远年轻 永远热泪盈眶</p>
        

        
            <br />
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                        <br />
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:&#122;&#97;&#110;&#103;&#98;&#111;&#64;&#115;&#106;&#116;&#117;&#46;&#101;&#100;&#117;&#46;&#99;&#110;" title="Email"></a>
                            
                                <a class="fa GitHub" href="https://github.com/zangbo" title="GitHub"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Word2Vec/">Word2Vec</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/个人网站/">个人网站</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/前端/">前端</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/梯度下降算法/">梯度下降算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>
                    </div>
                </section>
                
                
                

                
                
                <section class="switch-part switch-part3">
                
                    <div id="js-aboutme">SJTU在读研究生，机器学习相关，摄影爱好者，喜欢写一些随笔。</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">ZangBo</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.jpg" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">ZangBo</a></h1>
            </hgroup>
            
            <p class="header-subtitle">永远年轻 永远热泪盈眶</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:&#122;&#97;&#110;&#103;&#98;&#111;&#64;&#115;&#106;&#116;&#117;&#46;&#101;&#100;&#117;&#46;&#99;&#110;" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/zangbo" title="GitHub"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap"><article id="post-Tensorflow-官方文档学习笔记（二）" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/06/03/Tensorflow-官方文档学习笔记（二）/" class="article-date">
      <time datetime="2017-06-03T07:28:10.000Z" itemprop="datePublished">2017-06-03</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      TensorFlow 笔记（二）
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <script src="/assets/js/APlayer.min.js"> </script><p><excerpt in="" index="" |="" 首页摘要=""><br>本系列是对TensorFlow官方文档进行学习的总结，本篇介绍了利用TensorFlow搭建一个卷积神经网络，并用它来对MNIST数据集进行分类。<a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<p><br></p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这两天完成了官方文档第二部分的学习，之前我们用TensorFlow在MNIST数据集上实现了简单的Softmax回归，但准确率只有92%左右。因为这种方法忽略了图片的空间结构信息，而只是把图像展开成一维向量来输入。今天我们使用TensorFlow来搭建一个卷积神经网络，用它来对MNIST数据集进行分类。</p>
<p>接下来我们进行卷积神经网络的学习，我会一行行的解释用到的代码。</p>
<p><br></p>
<h1 id="初始化阶段"><a href="#初始化阶段" class="headerlink" title="初始化阶段"></a>初始化阶段</h1><p>首先是训练数据的准备工作，下面两行代码会下载并引用MNIST数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</div><div class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>, one_hot=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<p>然后我们启动一个会话，这里我们没有选择之前使用的<code>tf.Session()</code>，而是采用了交互式编程中更方便的Interactive类，这样我们可以在运行图的时候插入新的图，这在一些交互式环境比如ipython中更便利，我使用的是jupyter notebook，同样是交互式环境。如果没有使用 InteractiveSession ，那么需要在启动Session之前构建好整个计算图，然后才能启动该计算图。具体方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">sess = tf.InteractiveSession()</div></pre></td></tr></table></figure>
<p>接着我们定义两个占位符x和y_，分别用来输入图片数据和标签。它们均为二维向量，第一个维度用None来指代Batch大小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">x = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">784</span>])</div><div class="line">y_ = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">10</span>])</div></pre></td></tr></table></figure>
<p>为了创建这个模型，我们需要创建大量的权重和偏置项。这个模型中的权重在初始化时应该加入少量的噪声来打破对称性以及避免0梯度。由于我们使用的是ReLU神经元，因此比较好的做法是用一个较小的正数来初始化偏置项，以避免神经元节点输出恒为0的问题(dead neurons)。为了不在建立模型的时候反复做初始化操作，我们定义两个函数用于初始化。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></div><div class="line">  initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</div><div class="line">  <span class="keyword">return</span> tf.Variable(initial)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></div><div class="line">  initial = tf.constant(<span class="number">0.1</span>, shape=shape)</div><div class="line">  <span class="keyword">return</span> tf.Variable(initial)</div></pre></td></tr></table></figure>
<p>下面重点讲一下TensorFlow中的两个函数，它们分别用来做卷积操作和池化操作。</p>
<ul>
<li><p><code>tf.nn.conv2d(x,W,strides,padding)</code></p>
<p>参数有四个：</p>
<p>第一个参数x：4D的tensor，格式为[batch,height,width,channels]。</p>
<p>第二个参数W：核函数，同样是4D的tensor，格式为[height,width,in_channel,out_channel]。</p>
<p>第三个参数strides：步长，也是4D的tensor，格式为[1,stride,stride,1]，一般第一维和第四维都是1，因为很少有对batch和channel进行卷积计算。</p>
<p>第四个参数padding：分“SAME”或者“VALID”两种，前者会进行补0，使得卷积前后的尺寸相同，后者不补0。</p>
</li>
<li><p><code>tf.nn.max_pool(value, ksize, strides, padding)</code></p>
<p>参数是四个，和卷积很类似：</p>
<p>第一个参数value：需要池化的输入，一般池化层接在卷积层后面，所以输入通常是feature map，依然是[batch, height, width, channels]这样的shape</p>
<p>第二个参数ksize：池化窗口的大小，取一个四维向量，一般是[1, height, width, 1]，因为我们不想在batch和channels上做池化，所以这两个维度设为了1</p>
<p>第三个参数strides：和卷积类似，窗口在每一个维度上滑动的步长，一般也是[1, stride,stride, 1]</p>
<p>第四个参数padding：和卷积类似，可以取’VALID’ 或者’SAME’，返回一个Tensor，类型不变，shape仍然是[batch, height, width, channels]这种形式。</p>
</li>
</ul>
<p>这里我们的卷积使用1步长(stride size)，补0(padding size)模板，保证输出和输入是同一个大小。我们的池化用简单传统的2x2大小的模板做max pooling。为了代码更简洁，我们把这部分抽象成一个函数。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span></div><div class="line">  <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></div><div class="line">  <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</div></pre></td></tr></table></figure>
<p><br></p>
<h1 id="第一层卷积和池化"><a href="#第一层卷积和池化" class="headerlink" title="第一层卷积和池化"></a>第一层卷积和池化</h1><p>下面我们可以实现第一层了，它由一个卷积接一个max pooling完成。卷积在每个5x5的patch(卷积核)中算出32个特征。卷积的权重张量形状是[5, 5, 1, 32]，前两个维度是patch的大小，接着是输入的通道数目，最后是输出的通道数目。而对于每一个输出通道都有一个对应的偏置量。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">W_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>])</div><div class="line">b_conv1 = bias_variable([<span class="number">32</span>])</div></pre></td></tr></table></figure>
<p>为了用这一层，我们把x变成一个4d向量，其第2、第3维对应图片的高、宽，最后一维代表图片的颜色通道数(因为是灰度图所以这里的通道数为1，如果是rgb彩色图，则为3)。 然后我们进行卷积和池化操作，卷积后要用ReLU激活函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">x_image = tf.reshape(x, [<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</div><div class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</div><div class="line">h_pool1 = max_pool_2x2(h_conv1)</div></pre></td></tr></table></figure>
<p><br></p>
<h1 id="第二层卷积和池化"><a href="#第二层卷积和池化" class="headerlink" title="第二层卷积和池化"></a>第二层卷积和池化</h1><p>第二层中，每个5x5的patch会得到64个特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>])</div><div class="line">b_conv2 = bias_variable([<span class="number">64</span>])</div><div class="line"></div><div class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</div><div class="line">h_pool2 = max_pool_2x2(h_conv2)</div></pre></td></tr></table></figure>
<p><br></p>
<h1 id="全连接层fc1"><a href="#全连接层fc1" class="headerlink" title="全连接层fc1"></a>全连接层fc1</h1><p>现在，图片尺寸减小到7x7，我们加入一个有1024个神经元的全连接层，用于处理整个图片。我们把池化层输出的张量reshape成一些向量，乘上权重矩阵，加上偏置，然后对其使用ReLU。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">W_fc1 = weight_variable([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>])</div><div class="line">b_fc1 = bias_variable([<span class="number">1024</span>])</div><div class="line"></div><div class="line">h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</div><div class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</div></pre></td></tr></table></figure>
<p><br></p>
<h1 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h1><p>为了减少过拟合，我们采用dropout。说起dropout，这又是一门玄学了，dropout是指在网络的训练过程中，对于神经网络单元，按照一定的概率将其暂时从网络中丢弃，即随机让一些节点参数不工作。注意是暂时，对于随机梯度下降来说，由于是随机丢弃，故而每一个mini-batch都在训练不同的网络。实验证明这种方法能有效的减少过拟合。</p>
<p>我们用一个placeholder来代表神经元的输出在dropout中保持不变的概率，这样我们可以在训练过程中启用dropout，在测试过程中关闭dropout。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">keep_prob = tf.placeholder(tf.float32)</div><div class="line">h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</div></pre></td></tr></table></figure>
<p><br></p>
<h1 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h1><p>最后，我们添加一个softmax层，就像前面的单层softmax regression一样。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">W_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</div><div class="line">b_fc2 = bias_variable([<span class="number">10</span>])</div><div class="line">y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2</div></pre></td></tr></table></figure>
<p><br></p>
<h1 id="训练和评估"><a href="#训练和评估" class="headerlink" title="训练和评估"></a>训练和评估</h1><p>为了进行训练和评估，我们使用与之前简单的单层SoftMax神经网络模型几乎相同的一套代码，只是我们会用更加复杂的ADAM优化器来做梯度最速下降，在feed_dict中加入额外的参数keep_prob来控制dropout比例。然后每100次迭代输出一次日志。 一共进行了20000次迭代，batch_size是50。实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">cross_entropy = tf.reduce_mean(</div><div class="line">    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))</div><div class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</div><div class="line">correct_prediction = tf.equal(tf.argmax(y_conv,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div><div class="line">sess.run(tf.global_variables_initializer())</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20000</span>):</div><div class="line">  batch = mnist.train.next_batch(<span class="number">50</span>)</div><div class="line">  <span class="keyword">if</span> i%<span class="number">100</span> == <span class="number">0</span>:</div><div class="line">    train_accuracy = accuracy.eval(feed_dict=&#123;</div><div class="line">        x:batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">1.0</span>&#125;)</div><div class="line">    print(<span class="string">"step %d, training accuracy %g"</span>%(i, train_accuracy))</div><div class="line">  train_step.run(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">0.5</span>&#125;)</div><div class="line"></div><div class="line">print(<span class="string">"test accuracy %g"</span>%accuracy.eval(feed_dict=&#123;</div><div class="line">    x: mnist.test.images, y_: mnist.test.labels, keep_prob: <span class="number">1.0</span>&#125;))</div></pre></td></tr></table></figure>
<p>我用的jupyter notebook交互式环境。官网给出的训练时间大概是一个半小时，但我只用了16分钟左右就训练完了，可能官网给的是用CPU训练的参考时间。最后我们得到的准确率是99.2%，和官方文档得到的是一样的。这个网络模型是两层卷积两层池化两层全连接，最后一层全连接是softmax层。</p>
<p>至此我们就用TensorFlow从头到尾实现了一个卷积神经网络，中间涉及了很多矩阵运算，且都是4维向量之间的运算。期间用到了部分最优化里的东西，比如最速下降法，但并不深入。</p>
<p><br></p>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>深度学习到底还是个偏工程应用的学科，对于理论知识涉及面极广但并非很深入，而且很多地方还是玄学。比如dropout、迭代次数、学习率、batch size、正则项系数等等，这些参数全都要靠自己凭借经验调试，能出什么结果全凭运气。</p>
<p>好啦，我们关于卷积神经网络实现MNIST的内容就学习完啦，终于自己实现了一个网络hin开心，下面有时间会继续学习TensorFlow的其他部分。</p>
<p><br></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.tensorflow.org/get_started/mnist/pros" target="_blank" rel="external">Deep MNIST for Experts  |  TensorFlow</a>（需翻墙）</p>
<p><br></p>
</the>
      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2017/06/03/Tensorflow-官方文档学习笔记（二）/">TensorFlow 笔记（二）</a></p>
        <p><span>文章作者:</span><a href="/" title="回到主页">ZangBo</a></p>
        <p><span>发布时间:</span>2017-06-03, 15:28:10</p>
        <p><span>最后更新:</span>2017-06-25, 01:31:29</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2017/06/03/Tensorflow-官方文档学习笔记（二）/" title="TensorFlow 笔记（二）">http://zangbo.me/2017/06/03/Tensorflow-官方文档学习笔记（二）/</a>
            <span class="copy-path" data-clipboard-text="原文: http://zangbo.me/2017/06/03/Tensorflow-官方文档学习笔记（二）/　　作者: ZangBo" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/2017/06/04/关于随机梯度下降/">
                    深度学习中几种不同的梯度下降算法
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2017/06/02/Tensorflow-官方文档学习笔记（一）/">
                    TensorFlow 笔记（一）
                </a>
            </div>
        
    </nav>

  
  
  
    <div style="padding: 0; margin: 20px auto; width: 90%; text-align: center;">
      <br>
      <div>哎呦，不行了，要睡觉了，赏我 e(=2.72) 元咖啡钱吧，您的支持将鼓励我继续创作！</div>
      <br>
      <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
        <div class="btn btn-pay">打赏支持</div>
      </button>
      <br>
      <br>
      <div id="QR" style="display: none;">
        
          <div id="wechat" style="display: inline-block;">
            <img id="wechat_qr" src="/img/wechat-reward-qr.jpg" alt="ZangBo WeChat Pay"/>
            <p>微信打赏</p>
          </div>
        
        
          <div id="alipay" style="display: inline-block">
            <img id="alipay_qr" src="/img/alipay-reward-qr.jpg" alt="ZangBo Alipay"/>
            <p>支付宝打赏</p>
          </div>
        
        <br>
        <br>
      </div>
    </div>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#初始化阶段"><span class="toc-number">2.</span> <span class="toc-text">初始化阶段</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#第一层卷积和池化"><span class="toc-number">3.</span> <span class="toc-text">第一层卷积和池化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#第二层卷积和池化"><span class="toc-number">4.</span> <span class="toc-text">第二层卷积和池化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#全连接层fc1"><span class="toc-number">5.</span> <span class="toc-text">全连接层fc1</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Dropout"><span class="toc-number">6.</span> <span class="toc-text">Dropout</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#输出层"><span class="toc-number">7.</span> <span class="toc-text">输出层</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#训练和评估"><span class="toc-number">8.</span> <span class="toc-text">训练和评估</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#后记"><span class="toc-number">9.</span> <span class="toc-text">后记</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-number">10.</span> <span class="toc-text">参考</span></a></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-3 i,
        .toc-level-3 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                 "common":{"bdSnsKey":{},"bdText":"TensorFlow 笔记（二）　| ZangBo's Home　","bdMini":"2","bdMiniList":false,"bdPic":"http://zangbo.me/img/sharing.jpg","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>




    
        <section class="youyan" id="comments">
    <script>
        var loadComment = function(){
            var d = document, s = d.createElement('script');
            s.src = 'http://v2.uyan.cc/code/uyan.js?uid=2136080';
            (d.head || d.body).appendChild(s);
        }
    </script>
    
    <aside class="comment-bar">
        <a href="javascript:void(0);">
            <i class="fa fa-commenting-o animated infinite pulse"></i>
            <i class="fa fa-spinner fa-pulse"></i>
            <span class="count-comment"></span>
        </a>
    </aside>
    <script>
        var $commentBar = $("#comments aside.comment-bar");
        var load$hide = function(){
            $commentBar.find("a > i").toggle();
            loadComment();
            $commentBar.fadeOut(800);
        }
        $commentBar.click(function(){
            load$hide();
        })
        $commentBar.children("a").hover(function(){
            load$hide();
        })
        if (window.location.hash === "#comments") {
            load$hide();
        }
    </script>

    <div id="uyan_frame"></div>
</section>

    




    <div class="scroll" id="post-nav-button">
        
            <a href="/2017/06/04/关于随机梯度下降/" title="上一篇: 深度学习中几种不同的梯度下降算法">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2017/06/02/Tensorflow-官方文档学习笔记（一）/" title="下一篇: TensorFlow 笔记（一）">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/06/24/Tensorflow-官方文档学习笔记（三）/">TensorFlow 笔记（三）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/22/爬虫学习笔记（四）/">爬虫笔记（四）：获取某地历史天气数据</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/15/爬虫学习笔记（三）/">爬虫笔记（三）：BeautifulSoup基础</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/14/爬虫学习笔记（二）/">爬虫笔记（二）：Requests基础</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/13/爬虫学习笔记（一）/">爬虫笔记（一）：爬虫基础知识</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/13/编码相关知识/">编码相关知识</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/12/配置GithubPage二级域名/">配置GithubPage二级域名</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/12/送女友的生日礼物/">送给女友的生日礼物</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/06/Word2Vec之Negative-Sample/">Word2Vec笔记：Negative Sample</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/05/Word2Vec之skip-gram模型/">Word2Vec笔记：Skip-Gram模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/04/关于随机梯度下降/">深度学习中几种不同的梯度下降算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/03/Tensorflow-官方文档学习笔记（二）/">TensorFlow 笔记（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/02/Tensorflow-官方文档学习笔记（一）/">TensorFlow 笔记（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/01/Mac环境利用GitHub和Hexo搭建个人博客/">Mac环境利用GitHub和Hexo搭建个人博客</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/20/自我介绍/">欢迎来到我的小站</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2017 ZangBo
            </div>
            <div class="footer-right">
                Welcome to ZangBo's Blog
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>



<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-100951797-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->



    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

    <script>
        var originTitle = document.title;
        var titleTime;
        document.addEventListener("visibilitychange", function() {
            if (document.hidden) {
                document.title = "(つェ⊂) 我藏好了哦~ " + originTitle;
                clearTimeout(titleTime);
            }
            else {
                document.title = "(*´∇｀*) 被你发现啦~ " + originTitle;
                titleTime = setTimeout(function() {
                    document.title = originTitle;
                }, 2000);
            }
        })
    </script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>